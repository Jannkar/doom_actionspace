{"environment": "sim-to-sim", "freeze_vf": 0, "time_steps": 200000, "algorithm": "PPO", "exploration_fraction": 0.1, "ent_coef": 0.001, "save_dir": "PPO_sim-to-sim_vf_trainable", "mode": "train", "info": "Test runs to check how well PPO trains when network values are loaded and frozen from previous model (with freezing) with value function without freezing", "tensorboard_log": 1, "number_of_checkpoints": 50, "checkpoint": "", "load_params_from_previous_model": 1, "base_model": "./basemodels/PPO_basemodels/PPO_basemodel_1.pkl", "visualize": 0, "restore_value_function": 1, "action_space": "", "freeze_base_nn": 1, "rootdir": "/media/data1/jannkar/saved_trainings/"}